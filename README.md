# üõ†Ô∏è Projeto de Pipeline de Dados com MongoDB, Pandas, MySQL e Airflow

Este projeto une duas diferentes fontes de dados relacionais e n√£o relacionais utilizando um pipeline de dados completo que realiza as etapas de **extra√ß√£o, transforma√ß√£o e carga (ETL)** usando:

- **MongoDB** para armazenamento inicial dos dados (NoSQL)
- **Pandas** para transforma√ß√£o e limpeza
- **MySQL** como data warehouse final (SQL)
- **Airflow** para orquestra√ß√£o das tarefas
- **Requests** para extra√ß√£o via API
- **DAGs customizadas** para execu√ß√£o agendada

## üîß Funcionalidades

1. Coleta e simula√ß√£o de transa√ß√µes banc√°rias
2. Enriquecimento com dados de campanhas banc√°rias (Kaggle)
3. Integra√ß√£o com dados de fraude (Kaggle)
4. Armazenamento em camadas: Bronze, Silver e Gold
5. Camada Gold permite gera√ß√£o de insights e dashboards

## üß± Arquitetura em Camadas (Medallion Architecture)

- **Bronze**: Dados brutos simulados ou extra√≠dos
- **Silver**: Dados tratados, com enriquecimento e padroniza√ß√£o
- **Gold**: Dados prontos para an√°lise e gera√ß√£o de insights

## üõ†Ô∏è Tecnologias Usadas

- Python
- PySpark
- Apache Airflow
- Docker & Docker Compose
- MySQL
- MongoDB
- APIs p√∫blicas (IBGE)
- Pandas, Requests, Loguru

## üìä Exemplos de Insights

- Valor m√©dio e total de transa√ß√µes por estado
- Transa√ß√µes com suspeita de fraude por perfil de cliente
- Distribui√ß√£o de volume por banco de origem

## üöÄ Como Executar

1. Clone este reposit√≥rio:
```bash
git clone https://github.com/Leoosantoszl/Data_engineer/tree/main.git
cd seu-projeto
```

2. Suba a infraestrutura com Docker:
```bash
docker-compose up --build
```

3. Acesse o Airflow em `http://localhost:8080` e inicie a DAG principal.


> Projeto criado para fins educacionais, com dados simulados e p√∫blicos para an√°lise de dados financeiros.
